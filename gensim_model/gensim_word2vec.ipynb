{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import ast\n",
    "import glove_helper\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import keras\n",
    "from itertools import groupby\n",
    "from os.path import basename, splitext\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import regex as re\n",
    "import ast\n",
    "import glove_helper\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from itertools import groupby\n",
    "from os.path import basename, splitext\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathyzhou/anaconda3/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project='manifest-frame-203601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = (\n",
    "    \"\"\"\n",
    "    select distinct repo_path,c_content from w266_final.final_20k\n",
    "    \"\"\")\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "df = []\n",
    "for row in rows:\n",
    "    df.append([row.repo_path,row.c_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172413, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.columns = ['repo_path','content']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(docstring_list):\n",
    "    \n",
    "    \"\"\"takes a list of doc strings and converts to a single flat list of tokens\"\"\"\n",
    "    \n",
    "    tokens = [tf.keras.preprocessing.text.text_to_word_sequence(i) for i in docstring_list]\n",
    "    flat_tokens = [item for sublist in tokens for item in sublist]\n",
    "    flat_string = \" \".join(flat_tokens)\n",
    "    \n",
    "    return flat_string\n",
    "\n",
    "def get_docstrings(source):\n",
    "    \n",
    "    \"\"\"function to walk through parse tree and return list of docstrings\"\"\"\n",
    "    \n",
    "    NODE_TYPES = {\n",
    "    ast.ClassDef: 'Class',\n",
    "    ast.FunctionDef: 'Function/Method',\n",
    "    ast.Module: 'Module'\n",
    "    }\n",
    "    \n",
    "    docstrings = []\n",
    "    \n",
    "    try:\n",
    "        tree = ast.parse(source)\n",
    "    except:\n",
    "        return \" \"\n",
    "       \n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, tuple(NODE_TYPES)):\n",
    "            docstring = ast.get_docstring(node)\n",
    "            docstrings.append(docstring)\n",
    "    \n",
    "    docstrings =  [x for x in docstrings if x is not None]\n",
    "    clean_string = cleanup(docstrings)\n",
    "            \n",
    "    return clean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_path</th>\n",
       "      <th>content</th>\n",
       "      <th>docstrings</th>\n",
       "      <th>docstring2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ilogue/niprov tests/test_mediumviewer.py</td>\n",
       "      <td>#!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UndeadMastodon/Loltris Matrix.py</td>\n",
       "      <td>#!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...</td>\n",
       "      <td>prints a matrix to the console for debugging p...</td>\n",
       "      <td>[[prints, a, matrix, to, the, console, for, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anhstudios/swganh data/scripts/templates/objec...</td>\n",
       "      <td>#### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southpaw-TACTIC/TACTIC src/bin/example/add_fla...</td>\n",
       "      <td>import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scrapinghub/exporters exporters/writers/dropbo...</td>\n",
       "      <td>from collections import Counter\\nfrom exporter...</td>\n",
       "      <td>writes items to dropbox folder options availab...</td>\n",
       "      <td>[[writes, items, to, dropbox, folder, options,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           repo_path  \\\n",
       "0           ilogue/niprov tests/test_mediumviewer.py   \n",
       "1                   UndeadMastodon/Loltris Matrix.py   \n",
       "2  anhstudios/swganh data/scripts/templates/objec...   \n",
       "3  Southpaw-TACTIC/TACTIC src/bin/example/add_fla...   \n",
       "4  scrapinghub/exporters exporters/writers/dropbo...   \n",
       "\n",
       "                                             content  \\\n",
       "0  #!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...   \n",
       "1  #!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...   \n",
       "2  #### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...   \n",
       "3  import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...   \n",
       "4  from collections import Counter\\nfrom exporter...   \n",
       "\n",
       "                                          docstrings  \\\n",
       "0                                                      \n",
       "1  prints a matrix to the console for debugging p...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  writes items to dropbox folder options availab...   \n",
       "\n",
       "                                          docstring2  \n",
       "0                                               [[]]  \n",
       "1  [[prints, a, matrix, to, the, console, for, de...  \n",
       "2                                               [[]]  \n",
       "3                                               [[]]  \n",
       "4  [[writes, items, to, dropbox, folder, options,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['docstrings'] = [get_docstrings(x) for x in list(df['content'])]\n",
    "doc = []\n",
    "for i in df['docstrings']:\n",
    "    doc.append([i.split()])\n",
    "df['docstring2'] = doc\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(model):\n",
    "    # convert the wv word vectors into a numpy matrix that is suitable for insertion\n",
    "    # into our TensorFlow and Keras models\n",
    "    embedding_matrix = np.zeros((len(model.wv.vocab), 100))\n",
    "    for i in range(len(model.wv.vocab)):\n",
    "        embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = []\n",
    "vector_dim = 100\n",
    "for i in df['docstring2']:\n",
    "    #print(i[0])\n",
    " #   print(i)\n",
    "    if len(i[0]) ==0:\n",
    "        embed.append([[[0]]])\n",
    "    else:\n",
    "        model = Word2Vec(i, sg=1,iter=10, min_count=1, size=100, workers=4)\n",
    "        embedding_matrix = create_embedding_matrix(model)\n",
    "        embed.append([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_string_embed']=embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_path</th>\n",
       "      <th>content</th>\n",
       "      <th>docstrings</th>\n",
       "      <th>docstring2</th>\n",
       "      <th>doc_string_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ilogue/niprov tests/test_mediumviewer.py</td>\n",
       "      <td>#!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UndeadMastodon/Loltris Matrix.py</td>\n",
       "      <td>#!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...</td>\n",
       "      <td>prints a matrix to the console for debugging p...</td>\n",
       "      <td>[[prints, a, matrix, to, the, console, for, de...</td>\n",
       "      <td>[[[-0.0015476032858714461, 0.00098642380908131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anhstudios/swganh data/scripts/templates/objec...</td>\n",
       "      <td>#### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southpaw-TACTIC/TACTIC src/bin/example/add_fla...</td>\n",
       "      <td>import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scrapinghub/exporters exporters/writers/dropbo...</td>\n",
       "      <td>from collections import Counter\\nfrom exporter...</td>\n",
       "      <td>writes items to dropbox folder options availab...</td>\n",
       "      <td>[[writes, items, to, dropbox, folder, options,...</td>\n",
       "      <td>[[[-0.0005623144679702818, 0.00231970450840890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>astrofrog/sedfitter sedfitter/convolve/monochr...</td>\n",
       "      <td>from __future__ import print_function, divisio...</td>\n",
       "      <td>convolve all the model seds in a model directo...</td>\n",
       "      <td>[[convolve, all, the, model, seds, in, a, mode...</td>\n",
       "      <td>[[[-0.0003378069377504289, 0.00475694937631487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>materialsproject/pymatgen pymatgen/core/tests/...</td>\n",
       "      <td># coding: utf-8\\n# Copyright (c) Pymatgen Deve...</td>\n",
       "      <td>testing xcfunc api</td>\n",
       "      <td>[[testing, xcfunc, api]]</td>\n",
       "      <td>[[[-0.00021332580945454538, -0.000282575783785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dnerdy/namesync namesync/providers/cloudflare.py</td>\n",
       "      <td>import json\\n\\nfrom namesync.exceptions import...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kamyu104/LeetCode Python/path-sum-ii.py</td>\n",
       "      <td>from __future__ import print_function\\n# Time:...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>beiko-lab/gengis bin/Lib/site-packages/numpy/d...</td>\n",
       "      <td>\\r\\n# http://www.pgroup.com\\r\\n\\r\\nfrom numpy....</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           repo_path  \\\n",
       "0           ilogue/niprov tests/test_mediumviewer.py   \n",
       "1                   UndeadMastodon/Loltris Matrix.py   \n",
       "2  anhstudios/swganh data/scripts/templates/objec...   \n",
       "3  Southpaw-TACTIC/TACTIC src/bin/example/add_fla...   \n",
       "4  scrapinghub/exporters exporters/writers/dropbo...   \n",
       "5  astrofrog/sedfitter sedfitter/convolve/monochr...   \n",
       "6  materialsproject/pymatgen pymatgen/core/tests/...   \n",
       "7   dnerdy/namesync namesync/providers/cloudflare.py   \n",
       "8            kamyu104/LeetCode Python/path-sum-ii.py   \n",
       "9  beiko-lab/gengis bin/Lib/site-packages/numpy/d...   \n",
       "\n",
       "                                             content  \\\n",
       "0  #!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...   \n",
       "1  #!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...   \n",
       "2  #### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...   \n",
       "3  import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...   \n",
       "4  from collections import Counter\\nfrom exporter...   \n",
       "5  from __future__ import print_function, divisio...   \n",
       "6  # coding: utf-8\\n# Copyright (c) Pymatgen Deve...   \n",
       "7  import json\\n\\nfrom namesync.exceptions import...   \n",
       "8  from __future__ import print_function\\n# Time:...   \n",
       "9  \\r\\n# http://www.pgroup.com\\r\\n\\r\\nfrom numpy....   \n",
       "\n",
       "                                          docstrings  \\\n",
       "0                                                      \n",
       "1  prints a matrix to the console for debugging p...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  writes items to dropbox folder options availab...   \n",
       "5  convolve all the model seds in a model directo...   \n",
       "6                                 testing xcfunc api   \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "\n",
       "                                          docstring2  \\\n",
       "0                                               [[]]   \n",
       "1  [[prints, a, matrix, to, the, console, for, de...   \n",
       "2                                               [[]]   \n",
       "3                                               [[]]   \n",
       "4  [[writes, items, to, dropbox, folder, options,...   \n",
       "5  [[convolve, all, the, model, seds, in, a, mode...   \n",
       "6                           [[testing, xcfunc, api]]   \n",
       "7                                               [[]]   \n",
       "8                                               [[]]   \n",
       "9                                               [[]]   \n",
       "\n",
       "                                    doc_string_embed  \n",
       "0                                            [[[0]]]  \n",
       "1  [[[-0.0015476032858714461, 0.00098642380908131...  \n",
       "2                                            [[[0]]]  \n",
       "3                                            [[[0]]]  \n",
       "4  [[[-0.0005623144679702818, 0.00231970450840890...  \n",
       "5  [[[-0.0003378069377504289, 0.00475694937631487...  \n",
       "6  [[[-0.00021332580945454538, -0.000282575783785...  \n",
       "7                                            [[[0]]]  \n",
       "8                                            [[[0]]]  \n",
       "9                                            [[[0]]]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_search(words):\n",
    "    words_l = words.split()\n",
    "    model = Word2Vec(words_l, sg=1, min_count=1, size=100, workers=4)\n",
    "    embedding_matrix = create_embedding_matrix(model)\n",
    "    return (embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn(words, embeddings):\n",
    "    \n",
    "    search = embed_search(words)\n",
    "    distances = [scipy.spatial.distance.cosine(search[0], i[0][0][0]) for i in embeddings]\n",
    "    nn = np.argsort(np.asarray(distances))\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_code(search_terms, docstrings, embeddings, n):\n",
    "    \n",
    "    top_n = find_nn(search_terms, embeddings)[0:n]\n",
    "    code = [df['content'].iloc[i] for i in top_n]\n",
    "    \n",
    "    return code\n",
    "    #return top_n\n",
    "    \n",
    "#search = \"model for LSTM network\"\n",
    "doc_strings = list(df['docstrings'])\n",
    "embed_vecs = list(df['doc_string_embed'])\n",
    "\n",
    "#print(top_n_code(search, doc_strings, embed_vecs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathyzhou/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2010-2017 LE GOFF Vincent\n",
      "# All rights reserved.\n",
      "# \n",
      "# Redistribution and use in source and binary forms, with or without\n",
      "# modification, are permitted provided that the following conditions are met:\n",
      "# \n",
      "# * Redistributions of source code must retain the above copyright notice, this\n",
      "#   list of conditions and the following disclaimer.\n",
      "# * Redistributions in binary form must reproduce the above copyright notice,\n",
      "#   this list of conditions and the following disclaimer in the documentation\n",
      "#   and/or other materials provided with the distribution.\n",
      "# * Neither the name of the copyright holder nor the names of its contributors\n",
      "#   may be used to endorse or promote products derived from this software\n",
      "#   without specific prior written permission.\n",
      "# \n",
      "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n",
      "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT\n",
      "# OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "# POSSIBILITY OF SUCH DAMAGE.\n",
      "\n",
      "\n",
      "\"\"\"Fichier contenant le paramètre 'ejecter' de la commande 'canaux'.\"\"\"\n",
      "\n",
      "from primaires.interpreteur.masque.parametre import Parametre\n",
      "\n",
      "class PrmEjecter(Parametre):\n",
      "    \n",
      "    \"\"\"Commande 'canaux ejecter <canal> <joueur>'.\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self):\n",
      "        \"\"\"Constructeur du paramètre\"\"\"\n",
      "        Parametre.__init__(self, \"ejecter\", \"eject\")\n",
      "        self.schema = \"<canal> <nom_joueur>\"\n",
      "        self.aide_courte = \"éjecte un joueur\"\n",
      "        self.aide_longue = \\\n",
      "            \"Cette sous-commande permet d'éjecter un joueur. Il peut \" \\\n",
      "            \"néanmoins se reconnecter par la suite.\"\n",
      "    \n",
      "    def interpreter(self, personnage, dic_masques):\n",
      "        \"\"\"Interprétation du paramètre\"\"\"\n",
      "        if not dic_masques[\"canal\"].canal_existe:\n",
      "            personnage << \"|err|Vous n'êtes pas connecté à ce canal.|ff|\"\n",
      "        else:\n",
      "            canal = dic_masques[\"canal\"].canal\n",
      "            joueur = dic_masques[\"nom_joueur\"].joueur\n",
      "            if not personnage in canal.moderateurs and \\\n",
      "                    personnage is not canal.auteur and not \\\n",
      "                    personnage.est_immortel():\n",
      "                personnage << \"|err|Vous n'avez pas accès à cette option.|ff|\"\n",
      "            elif not personnage in canal.connectes:\n",
      "                personnage << \"|err|Vous n'êtes pas connecté à ce canal.|ff|\"\n",
      "            elif not joueur in canal.connectes:\n",
      "                personnage << \"|err|Ce joueur n'est pas connecté au \" \\\n",
      "                        \"canal.|ff|\"\n",
      "            elif joueur is personnage:\n",
      "                personnage << \"|err|Vous ne pouvez vous éjecter \" \\\n",
      "                        \"vous-même.|ff|\"\n",
      "            elif joueur in canal.moderateurs or joueur is canal.auteur:\n",
      "                personnage << \"|err|Vous ne pouvez éjecter ce joueur.|ff|\"\n",
      "            else:\n",
      "                canal.ejecter(joueur)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search1 = \"model for LSTM network\"\n",
    "query1 = (top_n_code(search1, doc_strings, embed_vecs, 5))\n",
    "print(query1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathyzhou/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\n",
      "\"\"\"\n",
      "Part of the World Generator project. \n",
      "\n",
      "author:  Bret Curtis\n",
      "license: LGPL v2\n",
      "\n",
      "This program is free software; you can redistribute it and/or\n",
      "modify it under the terms of the GNU General Public License\n",
      "version 2 as published by the Free Software Foundation.\n",
      "\n",
      "This program is distributed in the hope that it will be useful, but\n",
      "WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
      "General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program; if not, write to the Free Software\n",
      "Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n",
      "02110-1301 USA\n",
      "\"\"\"\n",
      "import sys\n",
      "from numpy import zeros\n",
      "\n",
      "if __name__ == '__main__': # handle multiple entry points\n",
      "    from constants import *\n",
      "else:\n",
      "    from .constants import *\n",
      "\n",
      "class Biomes():\n",
      "\n",
      "    def __init__(self, *args, **kwargs):\n",
      "        if len(args) == 0:\n",
      "            pass\n",
      "        elif len(args) == 5:\n",
      "            self.heightmap = args[0]\n",
      "            self.rainmap = args[1]\n",
      "            self.drainmap = args[2]\n",
      "            self.temperature = args[3]\n",
      "            self.worldW = len(self.heightmap)\n",
      "            self.worldH = len(self.heightmap[0])\n",
      "            self.biome = zeros((self.worldW, self.worldH))\n",
      "            self.biomeColourCode = zeros((self.worldW, self.worldH))\n",
      "            self.seaLevel = args[4] / 100.0 # reduce to 0.0 - 1.0 range\n",
      "            \n",
      "        else:\n",
      "            sys.exit('0 or 4 arguments only')\n",
      "\n",
      "    def run(self):\n",
      "        # calculate biome -- from scale of 0-400 ((oldValue-0) * (100-0)) / (400-0) + 0\n",
      "        for x in range(self.worldW):\n",
      "            for y in range(self.worldH):\n",
      "                \n",
      "                # new way\n",
      "                # for debugging, all areas are set to undefined\n",
      "                self.biome[x, y] = BIOME_TYPE_UNDEFINED\n",
      "                self.biomeColourCode[x, y] = COLOR_RED                \n",
      "                \n",
      "                # basic biome information based on elevation\n",
      "                if self.heightmap[x,y] <= self.seaLevel:       \n",
      "                    self.biome[x, y] = BIOME_TYPE_WATER         # Sealevel: e1-99 (0-98)\n",
      "                    self.biomeColourCode[x, y] = COLOR_BLUE\n",
      "                elif self.heightmap[x, y] > 0.75 and self.heightmap[x, y] <= 0.83:                     \n",
      "                    self.biome[x, y] = BIOME_TYPE_MOUNTAIN_LOW  # Mountain (Low): e300-332\n",
      "                    self.biomeColourCode[x, y] = COLOR_GRAY\n",
      "                elif self.heightmap[x, y] > 0.83 and self.heightmap[x, y] <= 0.91:            \n",
      "                    self.biome[x, y] = BIOME_TYPE_MOUNTAIN      # Mountain: e333-365\n",
      "                    self.biomeColourCode[x, y] = COLOR_ASH_GRAY\n",
      "                elif self.heightmap[x, y] > 0.91 and self.heightmap[x, y] <= 1.00:               \n",
      "                    self.biome[x, y] = BIOME_TYPE_MOUNTAIN_HIGH # Mountain (High): e366-400\n",
      "                    self.biomeColourCode[x, y] = COLOR_IVORY\n",
      "                else: # all other biomes are between elevations of 100 and 299 (25-74)\n",
      "                    if self.rainmap[x, y] < 0.10: # all rainfall between 0 and 9\n",
      "                        if self.drainmap[x, y] < 0.33:    # Desert (Sand): d0-32\n",
      "                            self.biome[x, y] = BIOME_TYPE_DESERT_SAND\n",
      "                            self.biomeColourCode[x, y] = COLOR_GOLDEN_YELLOW\n",
      "                        elif self.drainmap[x, y] < 0.50:    # Desert (Rock): d33-49\n",
      "                            self.biome[x, y] = BIOME_TYPE_DESERT_ROCK\n",
      "                            self.biomeColourCode[x, y] = COLOR_DARK_CHESTNUT\n",
      "                        else: # Desert (Badlands): r0-9, d50-100\n",
      "                            self.biome[x, y] = BIOME_TYPE_DESERT_BADLANDS\n",
      "                            self.biomeColourCode[x, y] = COLOR_TAUPE_PALE\n",
      "                    elif self.rainmap[x, y] >= 0.10 and self.rainmap[x, y] < 0.20:\n",
      "                        if self.drainmap[x, y] < 0.51:    # Grassland: r10-19, d0-50\n",
      "                            self.biome[x, y] = BIOME_TYPE_GRASSLAND\n",
      "                            self.biomeColourCode[x, y] = COLOR_GREEN\n",
      "                        else: # Hills: r10-65, d50-100\n",
      "                            self.biome[x, y] = BIOME_TYPE_HILLS\n",
      "                            self.biomeColourCode[x, y] = COLOR_EMERALD                            \n",
      "                    elif self.rainmap[x, y] >= 0.20 and self.rainmap[x, y] < 0.33:\n",
      "                        if self.drainmap[x, y] < 0.50:    # Savanna: r20-32, d0-50\n",
      "                            self.biome[x, y] = BIOME_TYPE_SAVANNA\n",
      "                            self.biomeColourCode[x, y] = COLOR_GREEN_YELLOW\n",
      "                        elif self.drainmap[x, y] < 0.80: # Hills: r10-65, d50-100\n",
      "                            self.biome[x, y] = BIOME_TYPE_HILLS\n",
      "                            self.biomeColourCode[x, y] = COLOR_EMERALD\n",
      "                        else:\n",
      "                            self.biome[x, y] = BIOME_TYPE_FOREST\n",
      "                            self.biomeColourCode[x, y] = COLOR_DARK_GREEN                                                          \n",
      "                    elif self.rainmap[x, y] >= 0.33 and self.rainmap[x, y] < 0.66:\n",
      "                        if self.drainmap[x, y] < 0.33:    # Marsh: r33-65, d0-32\n",
      "                            self.biome[x, y] = BIOME_TYPE_MARSH\n",
      "                            self.biomeColourCode[x, y] = 0x2B2E26\n",
      "                        elif self.drainmap[x, y] < 0.50:    # Shrubland: r33-65, d33-49\n",
      "                            self.biome[x, y] = BIOME_TYPE_SHRUBLAND\n",
      "                            self.biomeColourCode[x, y] = COLOR_FERN_GREEN\n",
      "                        elif self.drainmap[x, y] < 0.80:\n",
      "                            self.biome[x, y] = BIOME_TYPE_HILLS\n",
      "                            self.biomeColourCode[x, y] = COLOR_EMERALD\n",
      "                        else: # Hills: r10-65, d50-100                       \n",
      "                            self.biome[x, y] = BIOME_TYPE_FOREST\n",
      "                            self.biomeColourCode[x, y] = COLOR_DARK_GREEN                            \n",
      "                    else: # all other rainfall amounts (0.66 - 1.00)\n",
      "                        if self.drainmap[x, y] < 0.33:    # Swamp: r66-100, d0-32\n",
      "                            self.biome[x, y] = BIOME_TYPE_SWAMP\n",
      "                            self.biomeColourCode[x, y] = COLOR_AMETHYST\n",
      "                        else:  # Forest: r66-100, d33-100\n",
      "                            self.biome[x, y] = BIOME_TYPE_FOREST\n",
      "                            self.biomeColourCode[x, y] = COLOR_DARK_GREEN                    \n",
      "                                        \n",
      "    def biomeType(self, biome):\n",
      "        if biome == BIOME_TYPE_WATER: \n",
      "            result = \"Water\"\n",
      "        elif biome == BIOME_TYPE_GRASSLAND: \n",
      "            result = \"Grassland\"\n",
      "        elif biome == BIOME_TYPE_DESERT_SAND: \n",
      "            result = \"Sandy Desert\"\n",
      "        elif biome == BIOME_TYPE_DESERT_ROCK: \n",
      "            result = \"Rocky Desert\"\n",
      "        elif biome == BIOME_TYPE_MOUNTAIN_LOW: \n",
      "            result = \"Low Mountain\"\n",
      "        elif biome == BIOME_TYPE_MOUNTAIN_HIGH: \n",
      "            result = \"High Mountain\"\n",
      "        elif biome == BIOME_TYPE_SAVANNA: \n",
      "            result = \"Savanna\"\n",
      "        elif biome == BIOME_TYPE_MARSH: \n",
      "            result = \"Marsh\"\n",
      "        elif biome == BIOME_TYPE_SHRUBLAND: \n",
      "            result = \"Shrubland\"\n",
      "        elif biome == BIOME_TYPE_HILLS: \n",
      "            result = \"Hill\"\n",
      "        elif biome == BIOME_TYPE_SWAMP: \n",
      "            result = \"Swamp\"\n",
      "        elif biome == BIOME_TYPE_FOREST:\n",
      "            result = \"Forest\"\n",
      "        elif biome == BIOME_TYPE_DESERT_BADLANDS: \n",
      "            result = \"Badland\"\n",
      "        elif biome == BIOME_TYPE_MOUNTAIN: \n",
      "            result = \"Mountain\"                    \n",
      "        elif biome == BIOME_TYPE_UNDEFINED:\n",
      "            result = \"Undefined\"\n",
      "        else:\n",
      "            result = \"No, really... Undefined\"\n",
      "        return result\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    biomes = Biomes()\n",
      "    print(biomes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search2 = \"train a model for image recognition\"\n",
    "query2 = (top_n_code(search2, doc_strings, embed_vecs, 5))\n",
    "print(query2[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
